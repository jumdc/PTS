{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\diego\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\diego\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\diego\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\diego\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier, _tree, DecisionTreeRegressor, plot_tree\n",
    "from bokeh.plotting import figure\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from bokeh.io import show\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape Counter({0: 366, 1: 365})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84        87\n",
      "           1       0.86      0.86      0.86        96\n",
      "\n",
      "    accuracy                           0.85       183\n",
      "   macro avg       0.85      0.85      0.85       183\n",
      "weighted avg       0.85      0.85      0.85       183\n",
      "\n",
      "['loudness', 'danceability', 'valence', 'energy', 'speechiness', 'duration_ms', 'explicit', 'instrumentalness', 'mode', 'liveness', 'acousticness', 'key', 'tempo']\n"
     ]
    }
   ],
   "source": [
    "##### DECISON TREE (POPULARITY) #####\n",
    "\n",
    "# Loading the file\n",
    "df = pd.read_csv('data.csv', sep=\",\", encoding = \"ISO-8859-1\") \n",
    "\n",
    "# Drop non numerical variables\n",
    "df = df.drop(['artists'], axis=1)\n",
    "df = df.drop(['name'], axis=1)\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['release_date'], axis=1)\n",
    "df = df.drop(['year'], axis=1)\n",
    "\n",
    "\n",
    "# Sample to avoid oversampling\n",
    "df_ok = df[df['popularity'] > 80]\n",
    "df_ko = df.sample(df_ok.shape[0])\n",
    "df_test = pd.concat([df_ok, df_ko])\n",
    "\n",
    "# Create the famous variable \n",
    "df_test['famous'] = (df_test['popularity'] > 80).astype(int)\n",
    "\n",
    "# Delete popularity\n",
    "df_test = df_test.drop(['popularity'], axis=1)\n",
    "\n",
    "# split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_test.loc[:,df_test.columns != 'famous'],\n",
    "                                            df_test['famous'],\n",
    "                                            test_size =0.2,\n",
    "                                            random_state =42)\n",
    "\n",
    "print('Original data shape %s' % Counter(ytrain))\n",
    "\n",
    "# learn\n",
    "DR = DecisionTreeClassifier(criterion = \"gini\", max_depth = 5, random_state=12, min_samples_split=5)\n",
    "DR = DR.fit(xtrain, ytrain)\n",
    "\n",
    "# score\n",
    "y_pred = DR.predict(xtest)\n",
    "print(metrics.classification_report(ytest,y_pred))\n",
    "metrics.confusion_matrix(ytest,y_pred)\n",
    "export_graphviz(DR,\n",
    "            out_file=\"Arbre.dot\",\n",
    "            feature_names= xtest.columns,\n",
    "            class_names=['famous','not_famous'],\n",
    "            rounded =True,\n",
    "            proportion =False,\n",
    "            node_ids = True,\n",
    "            filled =True)\n",
    "\n",
    "variables = list(xtest.columns)\n",
    "counts = DR.feature_importances_\n",
    "\n",
    "#global feature importance\n",
    "x_range = sorted(variables, key =lambda x: counts[variables.index(x)], reverse=True)\n",
    "print(x_range)\n",
    "p = figure(x_range=x_range,\n",
    "           plot_height=420,\n",
    "           plot_width =1000,\n",
    "           title=\"Features importance\")\n",
    "\n",
    "p.vbar(x = variables, top = counts, width = 0.5)\n",
    "p.xaxis.major_label_orientation = 0.5\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    141307\n",
      "True      20846\n",
      "Name: top, dtype: int64\n",
      "32                 Loving You\n",
      "336          Indian Love Call\n",
      "760                    Always\n",
      "828             Runaway Train\n",
      "883                     Babel\n",
      "                 ...         \n",
      "169479            Be Yourself\n",
      "169483    Can I Get A Witness\n",
      "169497             I Miss You\n",
      "169500             Hallelujah\n",
      "169502       She's Mine Pt. 2\n",
      "Name: name, Length: 20846, dtype: object\n",
      "Original data shape Counter({True: 18844, False: 14509})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      0.46      0.56      3593\n",
      "        True       0.68      0.86      0.76      4746\n",
      "\n",
      "    accuracy                           0.69      8339\n",
      "   macro avg       0.69      0.66      0.66      8339\n",
      "weighted avg       0.69      0.69      0.67      8339\n",
      "\n",
      "['acousticness', 'duration_ms', 'speechiness', 'instrumentalness', 'danceability', 'liveness', 'valence', 'energy', 'loudness', 'explicit', 'key', 'mode', 'tempo']\n"
     ]
    }
   ],
   "source": [
    "##### DECISON TREE (HIT SONGS) #####\n",
    "\n",
    "# DataSet de départ\n",
    "data = pd.read_csv(\"data.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# DataSet des Top Hit (jusqu'à 2017)\n",
    "top_songs = pd.read_csv(\"top_data.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# On filtre donc notre DataSet de départ pour conserver seuelement les musiques avec date > 2017\n",
    "data_2017 = data[data[\"year\"]<2017]\n",
    "\n",
    "# On recherche l'existence des musiques dans le DataSet des Hit Songs pour créer une nouvelle variable de succès \n",
    "data_2017[\"top\"] = data_2017[\"name\"].isin(top_songs[\"title\"])\n",
    "                                                   \n",
    "# Affichage de la nouvelle variable\n",
    "print(data_2017[\"top\"].value_counts())\n",
    "print(data_2017[\"name\"][data_2017[\"top\"]==True])\n",
    "\n",
    "\n",
    "# Drop non numerical variables\n",
    "data_2017 = data_2017.drop(['artists'], axis=1)\n",
    "data_2017 = data_2017.drop(['name'], axis=1)\n",
    "data_2017 = data_2017.drop(['id'], axis=1)\n",
    "data_2017 = data_2017.drop(['release_date'], axis=1)\n",
    "data_2017 = data_2017.drop(['year'], axis=1)\n",
    "\n",
    "\n",
    "# Sample to avoid oversampling\n",
    "df_ok = data_2017[data_2017['top'] == 1]\n",
    "df_ko = data_2017.sample(df_ok.shape[0])\n",
    "df_test = pd.concat([df_ok, df_ko])\n",
    "\n",
    "# Delete popularity\n",
    "df_test = df_test.drop(['popularity'], axis=1)\n",
    "\n",
    "# split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_test.loc[:,df_test.columns != 'top'],\n",
    "                                            df_test['top'],\n",
    "                                            test_size =0.2,\n",
    "                                            random_state =42)\n",
    "\n",
    "print('Original data shape %s' % Counter(ytrain))\n",
    "\n",
    "# learn\n",
    "DR = DecisionTreeClassifier(criterion = \"gini\", max_depth = 5, random_state=12, min_samples_split=5)\n",
    "DR = DR.fit(xtrain, ytrain)\n",
    "\n",
    "# score\n",
    "y_pred = DR.predict(xtest)\n",
    "print(metrics.classification_report(ytest,y_pred))\n",
    "metrics.confusion_matrix(ytest,y_pred)\n",
    "export_graphviz(DR,\n",
    "            out_file=\"Arbre.dot\",\n",
    "            feature_names= xtest.columns,\n",
    "            class_names=['famous','not_famous'],\n",
    "            rounded =True,\n",
    "            proportion =False,\n",
    "            node_ids = True,\n",
    "            filled =True)\n",
    "\n",
    "variables = list(xtest.columns)\n",
    "counts = DR.feature_importances_\n",
    "\n",
    "#global feature importance\n",
    "x_range = sorted(variables, key =lambda x: counts[variables.index(x)], reverse=True)\n",
    "print(x_range)\n",
    "p = figure(x_range=x_range,\n",
    "           plot_height=420,\n",
    "           plot_width =1000,\n",
    "           title=\"Features importance\")\n",
    "\n",
    "p.vbar(x = variables, top = counts, width = 0.5)\n",
    "p.xaxis.major_label_orientation = 0.5\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
