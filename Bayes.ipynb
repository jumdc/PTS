{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary : \n",
    "    Define the sucess in order to categorize it : here 0 or 1 depending on a threshold (over 50,60,.. of popularity)\n",
    "    Perform a GNB (for continous variables)\n",
    "    Define the correctness : here since there are just a few 1 --> we define the accuracy by the number of right 1 \n",
    "    problem : not enough one to learn \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acousticness          artists  danceability  duration_ms  energy  explicit  \\\n",
      "0         0.995  Carl Woitschach         0.708       158648   0.195         0   \n",
      "1         0.988  Carl Woitschach         0.555       153967   0.421         0   \n",
      "2         0.990  Carl Woitschach         0.618       166075   0.180         0   \n",
      "3         0.988  Carl Woitschach         0.632       192734   0.345         0   \n",
      "4         0.993  Carl Woitschach         0.688       148095   0.334         0   \n",
      "\n",
      "                       id  instrumentalness  key  liveness  loudness  mode  \\\n",
      "0  6KbQ3uYMLKb5jDxLF7wYDD             0.563   10     0.151   -12.428     1   \n",
      "1  6OJjveoYwJdIt76y0Pxpxw             0.836    1     0.105    -9.878     1   \n",
      "2  7iOebgLNEGZu6jRp9upZdx             0.960    5     0.183   -14.288     1   \n",
      "3  7kf4F94PBSFhS7kYAXRaMb             0.905    8     0.219   -12.593     1   \n",
      "4  7vPhITAnwVUlmWb5fBbyoa             0.782   10     0.124    -8.898     1   \n",
      "\n",
      "                          name  popularity release_date  speechiness    tempo  \\\n",
      "0  Singende Bataillone 1. Teil           0         1928       0.0506  118.469   \n",
      "1          Per aspera ad astra           0         1928       0.0474  123.310   \n",
      "2  Singende Bataillone 2. Teil           0         1928       0.0402  120.220   \n",
      "3             Lore, Lore, Lore           0         1928       0.0448  121.738   \n",
      "4      Reserve hat Ruh 2. Teil           0         1928       0.0508  115.650   \n",
      "\n",
      "   valence  year  artistPop  \n",
      "0    0.779  1928        0.0  \n",
      "1    0.857  1928        0.0  \n",
      "2    0.802  1928        0.0  \n",
      "3    0.804  1928        0.0  \n",
      "4    0.764  1928        0.0  \n"
     ]
    }
   ],
   "source": [
    "dfData=pd.read_csv(\"data.csv\")\n",
    "dataArtist=pd.read_csv(\"data_by_artist.csv\",)\n",
    "dataArtist=dataArtist[[\"artists\",\"popularity\"]]#on garde que la colonne artist et popularité \n",
    "\n",
    "#Traitement artists \n",
    "#on fait une liste d'artiste \n",
    "dfData[\"artists\"]=dfData[\"artists\"].str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.replace(\"'\",'').str.split(\",\")\n",
    "dfData=dfData.explode(\"artists\")\n",
    "\n",
    "\n",
    "df=pd.merge(dfData,dataArtist,left_on=\"artists\",right_on=\"artists\")\n",
    "df=df.rename(columns={\"popularity_x\":\"popularity\",\"popularity_y\":\"artistPop\"})\n",
    "\n",
    "df=df.drop_duplicates(subset=['id'])#on garde un artiste pour chaque titre et on lui associe une popularité \n",
    "\n",
    "df.to_csv('popularitybyArtist.csv')\n",
    "#la popularité DES artists d'une chanson : soit on fait une somme soit une moyenne \n",
    "#faire une groupe sur le titre + les autres variables \n",
    "print(df.head())\n",
    "#print(merge.head())\n",
    "#df = df.sample(frac=1).reset_index(drop=True)\n",
    "#dfX=df[['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence','year']] \n",
    "#dfy : devient est-ce que la  chanson a appartenu au top 100 ou non "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe : binariation de popularity en fonction d'un certain threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [160050, 167740]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a79f040fd15f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\julie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [160050, 167740]"
     ]
    }
   ],
   "source": [
    "binarizer = Binarizer(threshold=70, copy=True)\n",
    "df['popularity']=binarizer.fit_transform(df['popularity'].values.reshape(df.shape[0], 1))\n",
    "#recup la colonne artist puis set, et mapping\n",
    "#calculer la précision sur les data qui valent 1\n",
    "dfy=df['popularity']\n",
    "X=dfX.to_numpy()\n",
    "y=dfy.to_numpy()\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.50,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nouvelle classe pour prédire le succès ou non : est ce que la musique fait partir du top 100?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-a91f4ab10557>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_2017[\"top\"] = data_2017[\"name\"].isin(top_songs[\"title\"])\n"
     ]
    }
   ],
   "source": [
    "# DataSet de départ : ici devient df \n",
    "#data = pd.read_csv(\"data.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# DataSet des Top Hit (jusqu'à 2017)\n",
    "top_songs = pd.read_csv(\"top_data.csv\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# On filtre donc notre DataSet de départ pour conserver seuelement les musiques avec date > 2017\n",
    "data_2017 = df[df[\"year\"]<2017]\n",
    "\n",
    "# On recherche l'existence des musiques dans le DataSet des Hit Songs pour créer une nouvelle variable de succès \n",
    "data_2017[\"top\"] = data_2017[\"name\"].isin(top_songs[\"title\"])\n",
    "dfX=data_2017[['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence','year']]\n",
    "y=data_2017[\"top\"].to_numpy()\n",
    "X=dfX.to_numpy()\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.50,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape Counter({False: 69820, True: 10205})\n",
      "Resampled data shape Counter({False: 69820, True: 69820})\n"
     ]
    }
   ],
   "source": [
    "#oversampling \n",
    "print('Original data shape %s' % Counter(yTrain))\n",
    "sm = SMOTE()\n",
    "xTrain, yTrain = sm.fit_resample(xTrain, yTrain)\n",
    "print('Resampled data shape %s' % Counter(yTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differenet Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BAYES with Scikit-lear**\n",
    "*first try with a gaussian distribution: fit continuous data*\n",
    "*NB : Gaussian Distribution, not pertinant\n",
    "*sur-apprentissage ?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 80025 points : 34053\n",
      "0.5744704779756327\n"
     ]
    }
   ],
   "source": [
    "def GNB(xTrain,yTrain,xTest,yTest):\n",
    "    gnb=GaussianNB()\n",
    "    yPred=gnb.fit(xTrain,yTrain).predict(xTest)\n",
    "    print(\"Number of mislabeled points out of a total %d points : %d\"% (xTest.shape[0], (yTest != yPred).sum()))     \n",
    "    print(metrics.accuracy_score(yTest, yPred))\n",
    "    return yPred\n",
    "yPred=GNB(xTrain,yTrain,xTest,yTest)\n",
    "#sns.jointplot(x=yTest, y=yPred, kind=\"kde\", color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Right prediction on 1-values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Prediction for sucess 0.8037864077669903\n"
     ]
    }
   ],
   "source": [
    "def OneCheck(yTest,yPred):\n",
    "    yTest1,yPred1=[],[]  \n",
    "    right1=0\n",
    "    for i,test in enumerate(yTest):\n",
    "        if test==1:\n",
    "            yTest1.append(test)\n",
    "            yPred1.append(yPred[i])\n",
    "            if yPred[i]==1:\n",
    "                right1+=1\n",
    "    print(\"Right Prediction for sucess\",right1/len(yTest1))\n",
    "OneCheck(yTest,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of Popularity ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "Number of mislabeled points out of a total 84955 points : 18804\n",
      "0.7786592902124654\n",
      "Right Prediction for sucess 0.302825726644298\n",
      "50\n",
      "Number of mislabeled points out of a total 84955 points : 20719\n",
      "0.7561179447943028\n",
      "Right Prediction for sucess 0.3038513210927004\n",
      "55\n",
      "Number of mislabeled points out of a total 84955 points : 21931\n",
      "0.7418515684774293\n",
      "Right Prediction for sucess 0.2980533289710453\n",
      "60\n",
      "Number of mislabeled points out of a total 84955 points : 22552\n",
      "0.7345418162556647\n",
      "Right Prediction for sucess 0.3045639979602244\n",
      "65\n",
      "Number of mislabeled points out of a total 84955 points : 23744\n",
      "0.7205108586898946\n",
      "Right Prediction for sucess 0.3005438637975881\n",
      "70\n",
      "Number of mislabeled points out of a total 84955 points : 23642\n",
      "0.7217114943205226\n",
      "Right Prediction for sucess 0.31398416886543534\n",
      "75\n",
      "Number of mislabeled points out of a total 84955 points : 21415\n",
      "0.7479253722559002\n",
      "Right Prediction for sucess 0.29041095890410956\n",
      "80\n",
      "Number of mislabeled points out of a total 84955 points : 16569\n",
      "0.8049673356482844\n",
      "Right Prediction for sucess 0.3021276595744681\n",
      "85\n",
      "Number of mislabeled points out of a total 84955 points : 8339\n",
      "0.9018421517273851\n",
      "Right Prediction for sucess 0.3150684931506849\n",
      "90\n",
      "Number of mislabeled points out of a total 84955 points : 7078\n",
      "0.9166853039844624\n",
      "Right Prediction for sucess 0.3684210526315789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pop in range(45,95,5):\n",
    "    print(pop)\n",
    "    df=pd.read_csv(\"data.csv\")\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    dfX=df[['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence','year']]\n",
    "    dfy=df['popularity']\n",
    "    binarizer = Binarizer(threshold=pop, copy=True)\n",
    "    df['popularity']=binarizer.fit_transform(df['popularity'].values.reshape(df.shape[0], 1))\n",
    "    #recup la colonne artist puis set, et mapping\n",
    "    #calculer la précision sur les data qui valent 1\n",
    "    X=dfX.to_numpy()\n",
    "    y=dfy.to_numpy()\n",
    "    xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.50,random_state=0)\n",
    "    sm = SMOTE()\n",
    "    xTrain, yTrain = sm.fit_resample(xTrain, yTrain)\n",
    "    GNB(xTrain,yTrain,xTest,yTest)\n",
    "    OneCheck(yTest,yPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**with scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "cols=['acousticness','danceability','duration_ms','energy','instrumentalness','liveness','loudness','speechiness','tempo','valence','year']\n",
    "def scaleColumns(df, cols2Scale):\n",
    "    for col in cols2Scale:\n",
    "        df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "    return df\n",
    "\n",
    "dfScaled=scaleColumns(df,cols)\n",
    "X=dfScaled[cols].to_numpy()\n",
    "y=dfy.to_numpy()\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "gnb=GaussianNB()\n",
    "yPred=gnb.fit(xTrain,yTrain).predict(xTest)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (xTest.shape[0], (yTest != yPred).sum()))\n",
    "metrics.accuracy_score(yTest, yPred)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**with discretization & binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acousticness                                            artists  \\\n",
      "0     -0.045706                  ['Steve Wariner', 'Garth Brooks']   \n",
      "1     -1.299841                                     ['Humble Pie']   \n",
      "2      1.284527  ['Johann Sebastian Bach', 'Amsterdam Toonkunst...   \n",
      "3     -0.744011                                     ['Tom Browne']   \n",
      "4     -0.831631                                      ['Aerosmith']   \n",
      "\n",
      "   danceability  duration_ms    energy  explicit                      id  \\\n",
      "0      1.544668    -0.850460  0.218434         0  4bjKZrfowKmAfzHrRhpfcQ   \n",
      "1     -1.506455    -0.386899  0.173556         0  6KL9kMRMmevqkJNnaVOeCJ   \n",
      "2     -2.282067    -0.910911 -0.551979         0  2PbDTYjEz0AWyNiumrr22n   \n",
      "3      0.575153    -0.080498  0.248353         0  3Yahrb4joLsIIdUSqyHJZ4   \n",
      "4     -1.152867     0.538460  1.811618         0  2pg89WdhaUgJzVX3YobOht   \n",
      "\n",
      "   instrumentalness  key  liveness  ...  acousticnessBin  danceabilityBin  \\\n",
      "0         -0.523507    9 -0.919650  ...              0.0              1.0   \n",
      "1         -0.523346    2 -0.856300  ...              0.0              0.0   \n",
      "2          1.474367    4 -0.156623  ...              1.0              0.0   \n",
      "3          2.114464    7  0.731406  ...              0.0              1.0   \n",
      "4         -0.522585    2 -0.207529  ...              0.0              0.0   \n",
      "\n",
      "  duration_msBin  energyBin instrumentalnessBin  livenessBin  loudnessBin  \\\n",
      "0            0.0        1.0                 0.0          0.0          1.0   \n",
      "1            0.0        1.0                 0.0          0.0          1.0   \n",
      "2            0.0        0.0                 1.0          0.0          0.0   \n",
      "3            0.0        1.0                 1.0          1.0          1.0   \n",
      "4            1.0        1.0                 0.0          0.0          1.0   \n",
      "\n",
      "   speechinessBin  tempoBin  valenceBin  \n",
      "0             0.0       0.0         1.0  \n",
      "1             0.0       1.0         0.0  \n",
      "2             0.0       0.0         0.0  \n",
      "3             0.0       0.0         1.0  \n",
      "4             0.0       1.0         0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#first n bins and then one hot encoder\n",
    "#discrete : mode\n",
    "#let's do an ordinalEncoder : since variable are ordinal and not nominal \n",
    "#(ordered categories but the distance is not known)\n",
    "\n",
    "\n",
    "disc = KBinsDiscretizer(n_bins=4, encode='uniform', strategy='uniform')\n",
    "columns=df.columns.values.tolist()\n",
    "cols=['acousticness','danceability', 'duration_ms', 'energy','instrumentalness',  'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
    "\n",
    "def Discretize(df,cols):\n",
    "    long=df.shape[0]\n",
    "    pass\n",
    "\n",
    "\n",
    "def Binarize(df,cols):\n",
    "    long=df.shape[0]\n",
    "    disc = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "    for c in cols:\n",
    "        mean=df[c].mean()\n",
    "        name=c+'Bin'\n",
    "        binarizer = Binarizer(threshold=mean, copy=True)\n",
    "        df[name]=binarizer.fit_transform(df[c].values.reshape(long, 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "dfB=Binarize(df,cols)\n",
    "print(dfB.head())\n",
    "\n",
    "dfBX=dfB[['acousticnessBin','danceabilityBin','energyBin','instrumentalnessBin','livenessBin','loudnessBin','speechinessBin','tempoBin','valenceBin']][:1000]\n",
    "#dfDX=dfD[['acousticnessDisc','danceabilityDisc','energyDisc','instrumentalnessDisc','livenessDisc','loudnessDisc','speechinessDisc','tempoDisc','valenceDisc']]\n",
    "dfBy=df['popularity'][:1000]\n",
    "XB=dfBX.to_numpy()\n",
    "yB=dfBy.to_numpy()\n",
    "xBTrain,xBTest,yBTrain,yBTest=train_test_split(XB,yB,test_size=0.50,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayes with SKlearn & binarized values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 500 points : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "yBPred=clf.fit(xBTrain, yBTrain).predict(xBTest)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (xBTest.shape[0], (yBTest != yBPred).sum()))\n",
    "metrics.accuracy_score(yBTest, yBPred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apprenticeship issues : too many data not varied "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
